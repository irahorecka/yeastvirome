{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f94a1295-cf53-4f80-be35-69a23b7e7a4d",
   "metadata": {},
   "source": [
    "# Transcriptomic Signature of Mycovirus Infection in Yeast\n",
    "\n",
    "## Objective\n",
    "To test whether infection by specific classes of mycoviruses leads to consistent transcriptional changes across *Saccharomyces cerevisiae* strains.\n",
    "\n",
    "## Data Sources\n",
    "- RNA-seq dataset from Caudal et al. (2024) covering hundreds of yeast strains\n",
    "- Mycovirus infection metadata per strain (e.g. presence/absence of Narnaviridae, Totiviridae, etc.)\n",
    "- Additional phenotype metadata (growth rate, ecology, clade, etc.)\n",
    "\n",
    "## Approach\n",
    "1. Load RNA-seq expression matrix (genes × strains)\n",
    "2. Group strains by virus infection status\n",
    "3. Perform differential expression analysis (infected vs uninfected)\n",
    "4. Run gene set enrichment (GO terms, pathways)\n",
    "5. Visualize results\n",
    "\n",
    "## Notes\n",
    "- This is an exploratory analysis.\n",
    "- Viral infection may correlate with strain background or ecology.\n",
    "- We will interpret findings cautiously and use controls when possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98138990-e66c-419d-a2a4-54f78cef34cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using delimiter: ','\n",
      "[info] Header has 30 columns.\n",
      "[info] Using columns: gene=systematic_name, strain=Strain, count=True, tpm=True\n",
      "[info] processed ~2,500,000 rows...\n",
      "[info] processed ~5,000,000 rows...\n",
      "[info] finished streaming ~6,314,973 rows.\n",
      "[ok] wrote counts → data/count_matrix.csv.gz  shape=(6454, 969)\n",
      "[ok] wrote TPM    → data/tpm_matrix.csv.gz  shape=(6454, 969)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Strain</th>\n",
       "      <th>AAA</th>\n",
       "      <th>AAB</th>\n",
       "      <th>AAD</th>\n",
       "      <th>AAE</th>\n",
       "      <th>AAG</th>\n",
       "      <th>AAH</th>\n",
       "      <th>AAI</th>\n",
       "      <th>AAK</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAM</th>\n",
       "      <th>...</th>\n",
       "      <th>XTRA_DGX</th>\n",
       "      <th>XTRA_DGY</th>\n",
       "      <th>XTRA_DHB</th>\n",
       "      <th>XTRA_DHD</th>\n",
       "      <th>XTRA_DHE</th>\n",
       "      <th>XTRA_DHJ</th>\n",
       "      <th>XTRA_DHK</th>\n",
       "      <th>XTRA_DHO</th>\n",
       "      <th>XTRA_DHQ</th>\n",
       "      <th>XTRA_DXL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systematic_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X1-EC1118_1F14_0012g</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X10-EC1118_1F14_0133g</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X1003-augustus_masked.YCM.7680</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X1004-augustus_masked.YCM.7680</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X1005-augustus_masked.YCM.7680</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 969 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Strain                          AAA       AAB       AAD       AAE       \\\n",
       "systematic_name                                                          \n",
       "X1-EC1118_1F14_0012g                 0.0      25.0       0.0       0.0   \n",
       "X10-EC1118_1F14_0133g                0.0    1368.0       0.0       0.0   \n",
       "X1003-augustus_masked.YCM.7680       0.0       0.0       0.0       0.0   \n",
       "X1004-augustus_masked.YCM.7680       0.0       0.0       0.0       0.0   \n",
       "X1005-augustus_masked.YCM.7680       0.0       0.0       0.0       0.0   \n",
       "\n",
       "Strain                          AAG       AAH       AAI       AAK       \\\n",
       "systematic_name                                                          \n",
       "X1-EC1118_1F14_0012g                 0.0      40.0       0.0       0.0   \n",
       "X10-EC1118_1F14_0133g                0.0      47.0       0.0       0.0   \n",
       "X1003-augustus_masked.YCM.7680       0.0       0.0       0.0       0.0   \n",
       "X1004-augustus_masked.YCM.7680       0.0       0.0       0.0       0.0   \n",
       "X1005-augustus_masked.YCM.7680       0.0       0.0       0.0       0.0   \n",
       "\n",
       "Strain                          AAL       AAM       ...  XTRA_DGX  XTRA_DGY  \\\n",
       "systematic_name                                     ...                       \n",
       "X1-EC1118_1F14_0012g                 0.0       0.0  ...       0.0       0.0   \n",
       "X10-EC1118_1F14_0133g                0.0       0.0  ...       0.0       0.0   \n",
       "X1003-augustus_masked.YCM.7680       0.0       0.0  ...       0.0       0.0   \n",
       "X1004-augustus_masked.YCM.7680       0.0       0.0  ...       0.0       0.0   \n",
       "X1005-augustus_masked.YCM.7680       0.0       0.0  ...       0.0       0.0   \n",
       "\n",
       "Strain                          XTRA_DHB  XTRA_DHD  XTRA_DHE  XTRA_DHJ  \\\n",
       "systematic_name                                                          \n",
       "X1-EC1118_1F14_0012g                 0.0       0.0       0.0       0.0   \n",
       "X10-EC1118_1F14_0133g                0.0       0.0       0.0       0.0   \n",
       "X1003-augustus_masked.YCM.7680       0.0       0.0       0.0       0.0   \n",
       "X1004-augustus_masked.YCM.7680       0.0       0.0       0.0       0.0   \n",
       "X1005-augustus_masked.YCM.7680       0.0       0.0       0.0       0.0   \n",
       "\n",
       "Strain                          XTRA_DHK  XTRA_DHO  XTRA_DHQ  XTRA_DXL  \n",
       "systematic_name                                                         \n",
       "X1-EC1118_1F14_0012g                 0.0       0.0       0.0       0.0  \n",
       "X10-EC1118_1F14_0133g                0.0       0.0       0.0       0.0  \n",
       "X1003-augustus_masked.YCM.7680       0.0       0.0       0.0       0.0  \n",
       "X1004-augustus_masked.YCM.7680       0.0       0.0       0.0       0.0  \n",
       "X1005-augustus_masked.YCM.7680       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 969 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import io, csv, textwrap\n",
    "\n",
    "# -----------------------\n",
    "# Config (edit this only)\n",
    "# -----------------------\n",
    "FILE = \"data/final_data_annotated_merged_04052022.tab\"  # .tab or .tab.gz/.zip ok\n",
    "# Column names (the file can have slight variations; we’ll auto-fallback too)\n",
    "CAND_GENE_COLS   = [\"systematic_name\", \"ORF\"]\n",
    "CAND_STRAIN_COLS = [\"Strain\", \"Standardized_name\"]\n",
    "COUNT_COL        = \"count\"\n",
    "TPM_COL          = \"tpm\"\n",
    "CHUNK            = 250_000\n",
    "OUT_DIR          = Path(\"./data/\")  # where to write matrices\n",
    "\n",
    "# -----------------------\n",
    "# Helpers\n",
    "# -----------------------\n",
    "def sniff_sep(path, default=\"\\t\", sample_bytes=1_000_000):\n",
    "    \"\"\"\n",
    "    Try to sniff delimiter from the first ~1MB. Fall back to default.\n",
    "    Works with compressed; pandas handles compression by extension later.\n",
    "    \"\"\"\n",
    "    p = Path(path)\n",
    "    # For zip/gz/bz2, pandas will handle decompression;\n",
    "    # We only need a guess — try reading a small block via pandas\n",
    "    try:\n",
    "        # First try tab quickly; if columns==1, try comma.\n",
    "        df_head = pd.read_csv(p, sep=\"\\t\", nrows=5, engine=\"python\", on_bad_lines=\"skip\")\n",
    "        if df_head.shape[1] > 1:\n",
    "            return \"\\t\"\n",
    "        df_head = pd.read_csv(p, sep=\",\", nrows=5, engine=\"python\", on_bad_lines=\"skip\")\n",
    "        if df_head.shape[1] > 1:\n",
    "            return \",\"\n",
    "    except Exception:\n",
    "        pass\n",
    "    return default\n",
    "\n",
    "def read_header(path, sep):\n",
    "    \"\"\"Read just the header to see available columns.\"\"\"\n",
    "    df = pd.read_csv(path, sep=sep, nrows=5, engine=\"python\", on_bad_lines=\"skip\")\n",
    "    return list(df.columns)\n",
    "\n",
    "def pick_first(existing, candidates):\n",
    "    \"\"\"Pick the first candidate that exists (case sensitive).\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in existing:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def aggregate_chunk(df, gene_col, strain_col, count_col=None, tpm_col=None):\n",
    "    \"\"\"Return (agg_counts, agg_tpms) grouped by (gene,strain).\"\"\"\n",
    "    keys = [gene_col, strain_col]\n",
    "    out_c = None\n",
    "    out_t = None\n",
    "    if count_col and count_col in df.columns:\n",
    "        out_c = (\n",
    "            df[keys + [count_col]]\n",
    "            .dropna(subset=keys)\n",
    "            .groupby(keys, as_index=False, sort=False)[count_col]\n",
    "            .sum()\n",
    "        )\n",
    "    if tpm_col and tpm_col in df.columns:\n",
    "        out_t = (\n",
    "            df[keys + [tpm_col]]\n",
    "            .dropna(subset=keys)\n",
    "            .groupby(keys, as_index=False, sort=False)[tpm_col]\n",
    "            .sum()\n",
    "        )\n",
    "    return out_c, out_t\n",
    "\n",
    "def merge_agg(existing, new, key_cols, value_col):\n",
    "    \"\"\"Merge two aggregated (gene,strain,value) tables by sum.\"\"\"\n",
    "    if existing is None:\n",
    "        return new\n",
    "    if new is None or new.empty:\n",
    "        return existing\n",
    "    merged = pd.concat([existing, new], ignore_index=True)\n",
    "    merged = merged.groupby(key_cols, as_index=False, sort=False)[value_col].sum()\n",
    "    return merged\n",
    "\n",
    "def to_wide(agg_df, gene_col, strain_col, value_col, fill=0.0, dtype=\"float32\"):\n",
    "    \"\"\"Pivot long -> wide (genes × strains).\"\"\"\n",
    "    if agg_df is None or agg_df.empty:\n",
    "        return None\n",
    "    wide = agg_df.pivot_table(index=gene_col, columns=strain_col, values=value_col, fill_value=fill, aggfunc=\"sum\")\n",
    "    # keep columns sorted for reproducibility\n",
    "    wide = wide.sort_index(axis=0).sort_index(axis=1)\n",
    "    return wide.astype(dtype)\n",
    "\n",
    "# -----------------------\n",
    "# Main loader\n",
    "# -----------------------\n",
    "def build_matrices(\n",
    "    path,\n",
    "    gene_cols=CAND_GENE_COLS,\n",
    "    strain_cols=CAND_STRAIN_COLS,\n",
    "    count_col=COUNT_COL,\n",
    "    tpm_col=TPM_COL,\n",
    "    chunksize=CHUNK,\n",
    "    out_dir=OUT_DIR,\n",
    "):\n",
    "    path = Path(path)\n",
    "    sep = sniff_sep(path)\n",
    "    print(f\"[info] Using delimiter: {repr(sep)}\")\n",
    "\n",
    "    cols = read_header(path, sep)\n",
    "    print(f\"[info] Header has {len(cols)} columns.\")\n",
    "    # Try to pick gene/strain columns\n",
    "    gene_col = pick_first(cols, gene_cols)\n",
    "    strain_col = pick_first(cols, strain_cols)\n",
    "\n",
    "    # Diagnostics if not found\n",
    "    if gene_col is None or strain_col is None:\n",
    "        msg = textwrap.dedent(f\"\"\"\n",
    "        [error] Could not find required columns.\n",
    "        - gene candidates tried: {gene_cols}\n",
    "        - strain candidates tried: {strain_cols}\n",
    "        - header columns: {cols[:20]}{' ...' if len(cols)>20 else ''}\n",
    "        \"\"\").strip()\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    if count_col not in cols and tpm_col not in cols:\n",
    "        raise ValueError(f\"[error] Neither '{count_col}' nor '{tpm_col}' found. Header preview: {cols[:20]}\")\n",
    "\n",
    "    print(f\"[info] Using columns: gene={gene_col}, strain={strain_col}, count={count_col in cols}, tpm={tpm_col in cols}\")\n",
    "\n",
    "    usecols = [gene_col, strain_col]\n",
    "    if count_col in cols: usecols.append(count_col)\n",
    "    if tpm_col   in cols: usecols.append(tpm_col)\n",
    "\n",
    "    # Aggregators (long format)\n",
    "    agg_counts = None\n",
    "    agg_tpms   = None\n",
    "\n",
    "    # Stream read\n",
    "    try:\n",
    "        # Newer pandas supports encoding_errors\n",
    "        reader = pd.read_csv(\n",
    "            path,\n",
    "            sep=sep,\n",
    "            usecols=usecols,\n",
    "            chunksize=chunksize,\n",
    "            dtype={gene_col:\"string\", strain_col:\"string\"},\n",
    "            engine=\"python\",\n",
    "            on_bad_lines=\"skip\",\n",
    "            encoding=\"utf-8\",\n",
    "            encoding_errors=\"replace\",   # ← keep row, replace bad bytes with �\n",
    "        )\n",
    "    except TypeError:\n",
    "        # Older pandas: no encoding_errors param. Fallback to latin1 which maps all bytes.\n",
    "        reader = pd.read_csv(\n",
    "            path,\n",
    "            sep=sep,\n",
    "            usecols=usecols,\n",
    "            chunksize=chunksize,\n",
    "            dtype={gene_col:\"string\", strain_col:\"string\"},\n",
    "            engine=\"python\",\n",
    "            on_bad_lines=\"skip\",\n",
    "            encoding=\"latin1\",           # ← accepts any byte, preserves row integrity\n",
    "        )\n",
    "\n",
    "    nrows = 0\n",
    "    for i, chunk in enumerate(reader, 1):\n",
    "        nrows += len(chunk)\n",
    "        ac, at = aggregate_chunk(chunk, gene_col, strain_col, count_col if count_col in chunk.columns else None,\n",
    "                                 tpm_col if tpm_col in chunk.columns else None)\n",
    "        agg_counts = merge_agg(agg_counts, ac, [gene_col, strain_col], count_col) if ac is not None else agg_counts\n",
    "        agg_tpms   = merge_agg(agg_tpms,   at, [gene_col, strain_col], tpm_col)   if at is not None else agg_tpms\n",
    "        if i % 10 == 0:\n",
    "            print(f\"[info] processed ~{nrows:,} rows...\")\n",
    "\n",
    "    print(f\"[info] finished streaming ~{nrows:,} rows.\")\n",
    "    # Pivot to wide\n",
    "    count_wide = to_wide(agg_counts, gene_col, strain_col, count_col) if agg_counts is not None else None\n",
    "    tpm_wide   = to_wide(agg_tpms,   gene_col, strain_col, tpm_col)   if agg_tpms   is not None else None\n",
    "\n",
    "    # Write to disk\n",
    "    out_paths = {}\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    if count_wide is not None:\n",
    "        p = out_dir / \"count_matrix.csv.gz\"\n",
    "        count_wide.to_csv(p, compression=\"gzip\")\n",
    "        out_paths[\"counts\"] = str(p)\n",
    "        print(f\"[ok] wrote counts → {p}  shape={count_wide.shape}\")\n",
    "\n",
    "    if tpm_wide is not None:\n",
    "        p = out_dir / \"tpm_matrix.csv.gz\"\n",
    "        tpm_wide.to_csv(p, compression=\"gzip\")\n",
    "        out_paths[\"tpm\"] = str(p)\n",
    "        print(f\"[ok] wrote TPM    → {p}  shape={tpm_wide.shape}\")\n",
    "\n",
    "    return count_wide, tpm_wide, out_paths\n",
    "\n",
    "# -----------------------\n",
    "# Run\n",
    "# -----------------------\n",
    "counts_df, tpm_df, outputs = build_matrices(FILE)\n",
    "counts_df.head() if counts_df is not None else tpm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe0dfa5-34bb-488c-b459-018db9896dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s_cerevisiae",
   "language": "python",
   "name": "s_cerevisiae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
